# Journal-Club
Time: Friday morning 10:00 - 10:30 AM, FGH 313

- [Journal-Club](#Journal-Club)
	- [Paper-Reading-Group](#paper-reading-group)
  
## Paper-Reading-Group

Agenda

|Date|Speaker|Paper|Remark|
|---|:---:|---|---|
|2025.10.30|Junlin Guo    <br>  （VLM & Reinforcement Learning）  |[《Med-R1: Reinforcement Learning for Generalizable Medical Reasoning in Vision-Language Models (IEEE TMI 2025)](https://arxiv.org/abs/2503.13939) 
|2025.10.30|Junlin Guo    <br>  （LLM Agent & Reinforcement Learning）  |[《Agent Learning via Early Experience》 (Arxiv）](https://arxiv.org/abs/2510.08558) 
|2025.10.30|Junlin Guo    <br>  （3D point cloud & 2D-3D Foundation Models）  |[《Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial Representations》 (Neurips2025）](https://arxiv.org/abs/2510.23607) 
|2025.10.24|Zhengyi Lu    <br>  （GUI Agent）  |[《Less is More: Empowering GUI Agent with Context-Aware Simplification》 (ArXiv）](https://arxiv.org/pdf/2507.03730) 
|2025.10.24|Zhengyi Lu    <br>  （MRI Geneartion）  |[《MRGen: Segmentation Data Engine for Underrepresented MRI Modalities》 (ArXiv）](https://arxiv.org/pdf/2412.04106)  
|2025.10.24|Zhengyi Lu    <br>  （MRI Segmentation）  |[《Teaching AI the Anatomy Behind the Scan: Addressing Anatomical Flaws in Medical Image Segmentation with Learnable Prior》 (ArXiv）](https://arxiv.org/pdf/2403.18878)
|2025.10.03|Tianyuan yao    <br>  （Vision Transformer）  |[《TransNeXt: Robust Foveal Visual Perception for Vision Transformers》 (CVPR 2024）](https://arxiv.org/abs/2311.17132)
|2025.10.03|Tianyuan yao    <br>  （Transformer）  |[《Agent Attention: On the Integration of Softmax and Linear Attention》 (ECCV 2024）](https://arxiv.org/abs/2312.08874) 
|2025.10.03|Tianyuan yao    <br>  （Transformer）  |[《Permutation Equivariance of Transformers and Its Applications》 (CVPR 2024）](https://arxiv.org/abs/2304.07735)  
|2025.09.19|Yanfan Zhu  <br>  （3D Object Reconstruction）  |[《Articulate-Anything: Automatic Modeling of Articulated Objects via a Vision-Language Foundation Model》 (ICLR2025）](https://arxiv.org/abs/2410.13882)  
|2025.09.19|Yanfan  <br>  （Generative Vision）  |[《4K4DGen: Panoramic 4D Generation at 4K Resolution》 (ICLR2025）](https://arxiv.org/abs/2406.13527) 
|2025.09.19|Yanfan Zhu  <br>  （Monocular Depth Estimation）  |[《Depth Pro: Sharp Monocular Metric Depth in Less Than a Second》 (ICLR2025）](https://arxiv.org/abs/2410.02073)
|2025.09.12|Junchao Zhu  <br>  （Vision Language Model）  |[《Two Effects, One Trigger: On the Modality Gap, Object Bias, and Information Imbalance in Contrastive Vision-Language Models》 (ICLR2025）](https://arxiv.org/abs/2404.07983)  
|2025.09.12|Junchao Zhu  <br>  （Vision Language Model）  |[《Open-Vocabulary Customization from CLIP via Data-Free Knowledge Distillation》 (ICLR2025）](https://proceedings.iclr.cc/paper_files/paper/2025/hash/8c96b559340daa7bb29f56ccfbbc9c2f-Abstract-Conference.html) 
|2025.09.12|Junchao Zhu  <br>  （Vision Language Model）  |[《MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language Models》 (ICLR2025）](https://arxiv.org/abs/2410.13085)
|2025.08.29|Chongyu Qu  <br>  （Efficient Generative Model）  |[《Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models》 (ICLR2025）](https://arxiv.org/abs/2410.10733)
|2025.08.29|Chongyu Qu  <br>  （Efficient Generative Model）  |[《DC-AE 1.5: Accelerating Diffusion Model Convergence with Structured Latent Space》 (ICCV 2025）](https://arxiv.org/abs/2508.00413)
|2025.08.29|Chongyu Qu  <br>  （Efficient Generative Model）  |[《DC-AR: Efficient Masked Autoregressive Image Generation with Deep Compression Hybrid Tokenizer》 (ICCV 2025）](https://arxiv.org/abs/2507.04947)
|2025.08.15|Junlin Guo    <br>  （Vision Foundation Model）  |[《DINOv3》 (ArXiv）](https://arxiv.org/abs/2508.10104)  
|2025.08.15|Junlin Guo    <br>  （Vision Foundation Model）  |[《Galileo: Learning Global & Local Features of Many Remote Sensing Modalities》 (ICLR2025）](https://arxiv.org/abs/2502.09356)  
|2025.08.15|Junlin Guo    <br>  （Vision Foundation Model）  |[《AnySat: One Earth Observation Model for Many Resolutions, Scales, and Modalities》 (CVPP2025）](https://arxiv.org/abs/2412.14123)  
|2025.08.08|Zhengyi Lu    <br>  （Image Refinement）  |[《IMPRINT: Generative Object Compositing by Learning Identity-Preserving Representation》 (ArXiv）](https://arxiv.org/abs/2403.10701)  
|2025.08.08|Zhengyi Lu    <br>  （Image Refinement）  |[《Refine-by-Align: Reference-Guided Artifacts Refinement through Semantic Alignment》 (ArXiv）](https://arxiv.org/abs/2412.00306)  
|2025.08.08|Zhengyi Lu    <br>  （Image Refinement）  |[《Type-R: Automatically Retouching Typos for Text-to-Image Generation》 (ArXiv）](https://arxiv.org/abs/2411.18159)
|2025.08.01|Tianyuan yao    <br>  （LLM）  |[《SepLLM: Accelerate Large Language Models by Compressing One Segment into One Separator》 (ICML2025）](https://arxiv.org/pdf/2412.12094) 
|2025.08.01|Tianyuan yao    <br>  （diffusion, CNN）  |[《DiC: Rethinking Conv3x3 Designs in Diffusion Models》 (CVPR2025）](https://arxiv.org/pdf/2501.00603)  
|2025.08.01|Tianyuan yao    <br>  （LLM）  |[《Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation of Causal Transformers without Position》 (Google DeepMind）](https://arxiv.org/pdf/2507.10524)  
|2025.07.25 |Xindong Zheng    <br>  (Semi-Supervised Segmentation)|[《Annotation Ambiguity Aware Semi-Supervised Medical Image Segmentation》 (CVPR2025）](https://openaccess.thecvf.com/content/CVPR2025/papers/Kumari_Annotation_Ambiguity_Aware_Semi-Supervised_Medical_Image_Segmentation_CVPR_2025_paper.pdf)  
|2025.07.25 |Xindong Zheng    <br>  (Diffusion)|[《Anatomical Consistency and Adaptive Prior-informed Transformation for Multi-contrast MR Image Synthesis via Diffusion Model》 (CVPR2025）](https://openaccess.thecvf.com/content/CVPR2025/papers/Shin_Anatomical_Consistency_and_Adaptive_Prior-informed_Transformation_for_Multi-contrast_MR_Image_CVPR_2025_paper.pdf)  
|2025.07.25 | Xindong Zheng    <br>  (Anomaly Detection)|[《PIAD: Pose and Illumination agnostic Anomaly Detection》 (CVPR2025）](https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_PIAD_Pose_and_Illumination_agnostic_Anomaly_Detection_CVPR_2025_paper.pdf)
|2025.07.18|Marilyn Lionts    <br>  （VLM）  |[《Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Vision-Language Models》 (CVPR2025）](https://arxiv.org/pdf/2409.17146)  
|2025.07.18|Marilyn Lionts    <br>  （Computer Vision Video）  |[《Navigation World Models》 (CVPR2025）](https://arxiv.org/pdf/2412.03572)  
|2025.07.18|Marilyn Lionts    <br>  （MLLM）  |[《Generative Multimodal Pretraining with Discrete Diffusion Timestep Tokens》 (CVPR2025）](https://arxiv.org/pdf/2504.14666)  
|2025.06.27|Yanfan Zhu    <br>  （ReID）  |[《From Poses to Identity: Training‑Free Person Re‑Identification via Feature Centralization》 (CVPR2025）](https://arxiv.org/abs/2503.00938)  
|2025.06.27|Yanfan Zhu    <br>  （Reconstruction）  |[《Reconstructing Humans with a Biomechanically Accurate Skeleton》 (CVPR2025）](https://arxiv.org/abs/2503.21751v1)   
|2025.06.27|Yanfan Zhu    <br>  （Reconstruction）  |[《Fast3R: Towards 3D Reconstruction of 1000+ Images in One Forward Pass》 (CVPR2025）](https://arxiv.org/abs/2501.13928) 
|2025.06.20|Junlin Guo    <br>  （Model Explanation & Visualization）  |[《Interpreting Object-level Foundation Models via Visual Precision Search》 (CVPR2025）](https://arxiv.org/pdf/2411.16198)  
|2025.06.20|Junlin Guo    <br>  （3D Visual Grounding & Transformer）  |[《VGGT: Visual Geometry Grounded Transformer》 (CVPR2025）](https://vgg-t.github.io/)  
|2025.06.20|Junlin Guo    <br>  （Pathology & Foundation Model）  |[《A whole-slide foundation model for digital pathology from real-world data》 (Nature 2024）](https://www.nature.com/articles/s41586-024-07441-w#Fig1)  
|2025.05.16|Zhengyi Lu    <br>  （3D Diffusion& Mesh）  |[《MIDI: Multi-Instance Diffusion for Single Image to 3D Scene Generation》 (ArXiv）](https://arxiv.org/pdf/2412.03558)  
|2025.05.16|Zhengyi Lu    <br>  （3D Diffusion& Mesh）  |[《One-2-3-45++: Fast Single Image to 3D Objects with Consistent Multi-View Generation and 3D Diffusion》 (ArXiv）](https://arxiv.org/pdf/2311.07885)  
|2025.05.16|Zhengyi Lu    <br>  （3D Diffusion& Mesh）  |[《One-2-3-45: Any Single Image to 3D Mesh in 45 Seconds without Per-Shape Optimization》 (ArXiv）](https://arxiv.org/pdf/2306.16928)
|2025.04.25|Yuechen Yang    <br>  （Pathomics）  |[《Comparison and Optimization of Cellular Neighbor Preference Methods for Quantitative Tissue Analysis》](https://www.biorxiv.org/content/10.1101/2025.03.31.646289v2)
|2025.04.25|Yuechen Yang    <br>  （Pathomics）  |[《Clinical Relevance of Computational Pathology Analysis of Interplay Between Kidney Microvasculature and Interstitial Microenvironment》 (ArXiv）](https://pubmed.ncbi.nlm.nih.gov/39714939)
|2025.04.25|Yuechen Yang    <br>  （Pathomics）  |[《Large-scale extraction of interpretable features provides new insights into kidney histopathology – A proof-of-concept study](https://pmc.ncbi.nlm.nih.gov/articles/PMC9576990/)
|2025.04.25|Chongyu Qu    <br>  （Quantization Method）  |[《SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models》 (ArXiv）](https://arxiv.org/abs/2211.10438)
|2025.04.25|Chongyu Qu    <br>  （Quantization Method）  |[《SVDQuant: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion Models》 (ArXiv）](https://arxiv.org/abs/2411.05007)
|2025.04.25|Chongyu Qu    <br>  （Quantization Method）  |[《QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs》 (ArXiv）](https://arxiv.org/abs/2404.00456)  
|2025.04.18|Yanfan Zhu    <br>  （TDA）  |[《TopOC: Topological Deep Learning for Ovarian and Breast Cancer Diagnosis》 (ArXiv）](https://arxiv.org/abs/2410.09818)  
|2025.04.18|Yanfan Zhu    <br>  （TDA）  |[《PI-Att: Topology Attention for Segmentation Networks through Adaptive Persistence Image Representation》 (ArXiv）](https://arxiv.org/abs/2408.08038)   
|2025.04.18|Yanfan Zhu    <br>  （TDA）  |[《Topologically Faithful Multi-class Segmentation in Medical Images》 (ArXiv）](https://arxiv.org/abs/2403.11001)  
|2025.04.11|Junchao Zhu	<br>	(Diffusion)	|[《DiffSensei: Bridging Multi-Modal LLMs and Diffusion Models for Customized Manga Generation》 (CVPR 2025）](https://arxiv.org/pdf/2412.07589)
|2025.04.11|Junchao Zhu	<br>	(Generation Model)	|[《Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step》 (ArXiv Jan 2025）](https://arxiv.org/pdf/2501.13926)
|2025.04.11|Junchao Zhu	<br>	(Diffusion)	|[《Reconstruction vs. Generation: Taming Optimization Dilemma in Latent Diffusion Models》 (CVPR 2025）](https://arxiv.org/pdf/2501.01423)
|2025.04.04|Marilyn Lionts	<br>	(Diffusion)	|[《Unified Multimodal Discrete Diffusion》 (ArXiv March 2025）](https://arxiv.org/pdf/2503.20853#cite.li2022diffusionlmimprovescontrollabletext)
|2025.04.04|Marilyn Lionts	<br>	(AI Ethics)	|[《Users Favor LLM-Generated Content—Until They Know It’s AI》 (ArXiv February 2025）](https://arxiv.org/pdf/2503.16458)
|2025.04.04|Marilyn Lionts	<br>	(AI Ethics)	|[《Position: Model Collapse Does Not Mean What You Think》 (ArXiv March 2025）](https://arxiv.org/pdf/2503.03150)
|2025.03.28|Tianyuan yao    <br>  （Transformer, PE）  |[《RoFormer: Enhanced Transformer with Rotary Position Embedding》 (ArXiv）](https://arxiv.org/abs/2104.09864) 
|2025.03.28|Tianyuan yao    <br>  （Transformer, PE）  |[《Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer》 (ArXiv）](https://arxiv.org/abs/1910.10683)  
|2025.03.28|Tianyuan yao    <br>  （Transformer, PE）  |[《Length Generalization of Causal Transformers without Position Encoding》 (ArXiv）](https://arxiv.org/abs/2404.12224)  
|2025.03.07|Zhengyi Lu    <br>  （Cinemagraph）  |[《StyleCineGAN: Landscape Cinemagraph Generation using a Pre-trained StyleGAN》 (ArXiv）](https://arxiv.org/abs/2403.14186)  
|2025.03.07|Zhengyi Lu    <br>  （GAN&Diffusion）  |[《Diffusion-driven GAN Inversion for Multi-Modal Face Image Generation》 (ArXiv）](https://arxiv.org/abs/2405.04356)  
|2025.03.07|Zhengyi Lu    <br>  （GAN&Diffusion）  |[《When StyleGAN Meets Stable Diffusion: a W+ Adapter for Personalized Image Generation》 (ArXiv）](https://arxiv.org/abs/2311.17461)  
|2025.02.28|Yanfan Zhu    <br>  （LLM Sparsity）  |[《Turbo Sparse: Achieving LLM SOTA Performance with Minimal Activated Parameters》 (ArXiv）](https://arxiv.org/abs/2406.05955)  
|2025.02.28|Yanfan Zhu    <br>  （Framework Acceleration）  |[《A Multi-Level Framework for Accelerating Training Transformer Models》 (ArXiv）](https://arxiv.org/abs/2404.07999)   
|2025.02.28|Yanfan Zhu    <br>  （Hardware Acceleration）  |[《Flash Attention-3: Fast and Accurate Attention with Asynchrony and Low-precision》 (ArXiv）](https://arxiv.org/abs/2407.08608)  
|2025.02.21|Yuechen Yang    <br>  （Mesh Gereration）  |[《MeshFormer: High-Quality Mesh Generation with 3D-Guided Reconstruction Model》 (ArXiv）](https://arxiv.org/abs/2408.10198)  
|2025.02.21|Yuechen Yang    <br>  （Mesh Gereration）  |[《MeshAnything: Artist-Created Mesh Generation with Autoregressive Transformers》 (ArXiv）](https://arxiv.org/abs/2406.10163)   
|2025.02.21|Yuechen Yang    <br>  （Mesh Gereration）  |[《MeshAnything V2: Artist-Created Mesh Generation With Adjacent Mesh Tokenization》 (ArXiv）](https://arxiv.org/abs/2408.02555)   
|2025.01.17|Juming Xiong  <br>  （PPT Agent）  |[《PPTAgent: Generating and Evaluating Presentations Beyond Text-to-Slides》 (ArXiv）](https://arxiv.org/abs/2501.03936)
|2025.01.17|Juming Xiong  <br>  （PPT Agent）  |[《AUTOPRESENT: Designing Structured Visuals from Scratch》 (ArXiv）](https://www.arxiv.org/abs/2501.00912)
|2025.01.17|Juming Xiong  <br>  （PPT Agent）  |[《Enhancing Presentation Slide Generation by LLMs with a Multi-Staged End-to-End Approach》 (ArXiv）](https://arxiv.org/abs/2406.06556)
|2025.01.10|Tianyuan Yao    <br>  （Large Language Model）  |[《DeepSeek-V3 Technical Report》 (ArXiv）](https://arxiv.org/pdf/2412.19437)
|2025.01.10|Tianyuan Yao    <br>  （Large Language Model）  |[《DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model》 (ArXiv）](https://arxiv.org/pdf/2405.04434)
|2025.01.10|Tianyuan Yao    <br>  （Large Language Model）  |[《DeepSeek LLM: Scaling Open-Source Language Models with Longtermism》 (ArXiv）](https://arxiv.org/pdf/2401.02954)
|2024.12.13|Marilyn Lionts    <br>  （Foundation Model）  |[《Solaris: A Foundation Model of the Sun》](https://arxiv.org/pdf/2411.16339)
|2024.12.13|Marilyn Lionts    <br>  （LLM）  |[《Star Attention: Efficient LLM Inference over Long Sequences》](https://arxiv.org/pdf/2411.17116)
|2024.12.13|Marilyn Lionts    <br>  （LLM）  |[《Ring Attention with Blockwise Transformers for Near-Infinite Context》   (Neurips2024)](https://arxiv.org/pdf/2310.01889)
|2024.12.6|Junchao Zhu    <br>  （Generative model）  |[《Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction》   (Neurips2024)](https://arxiv.org/pdf/2404.02905)
|2024.12.6|Junchao Zhu    <br>  （LLM）  |[《RHO-1: Not All Tokens Are What You Need》   (Neurips2024)](https://arxiv.org/pdf/2404.07965)
|2024.12.6|Junchao Zhu    <br>  （GNN）  |[《Dynamic Graph Representation with Knowledge-Aware Attention for Histopathology Whole Slide Image Analysis》   (CVPR2024)](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_Dynamic_Graph_Representation_with_Knowledge-aware_Attention_for_Histopathology_Whole_Slide_CVPR_2024_paper.pdf)
|2024.10.18|Junchao Zhu    <br>  （GNN+Super-resolution）  |[《Image Processing GNN: Breaking Rigidity in Super-Resolution》   (CVPR2024)](https://openaccess.thecvf.com/content/CVPR2024/papers/Tian_Image_Processing_GNN_Breaking_Rigidity_in_Super-Resolution_CVPR_2024_paper.pdf)
|2024.10.18|Junchao Zhu    <br>  （GNN+Finetuning）  |[《Fine-tuning Graph Neural Networks by Preserving Graph Generative Patterns》   (AAAI2024)](https://arxiv.org/abs/2312.13583)
|2024.10.18|Junchao Zhu    <br>  （Spatial Transcriptomics）  |[《Accurate spatial gene expression prediction by integrating multi-resolution features》   (CVPR2024)](https://openaccess.thecvf.com/content/CVPR2024/papers/Chung_Accurate_Spatial_Gene_Expression_Prediction_by_Integrating_Multi-Resolution_Features_CVPR_2024_paper.pdf)
|2024.10.4|Yuechen Yang Guo    <br>  （Generative model）  |[《Towards Accurate Image Coding:  Improved Autoregressive Image Generation with Dynamic Vector Quantization》   (CVPR2023)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Towards_Accurate_Image_Coding_Improved_Autoregressive_Image_Generation_With_Dynamic_CVPR_2023_paper.pdf)
|2024.10.4|Yuechen Yang    <br>  （Generative model）  |[《Not All Image Regions Matter: Masked Vector Quantization for Autoregressive Image Generation》   (CVPR2023)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Not_All_Image_Regions_Matter_Masked_Vector_Quantization_for_Autoregressive_CVPR_2023_paper.pdf)
|2024.10.4|Yuechen Yang    <br>  （Generative model）  |[《Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction》  ](https://arxiv.org/abs/2404.02905)
|2024.09.27|Junlin Guo    <br>  （Vision-language model）  |[《Enhancing Representation in Radiography-Reports Foundation Model: A Granular Alignment Algorithm Using Masked Contrastive Learning》   (Nature Communication)](https://arxiv.org/abs/2309.05904)
|2024.09.27|Junlin Guo    <br>  （Vision-language model）  |[《Dr-LLaVA: Visual Instruction Tuning with Symbolic Clinical Grounding》   (Arxiv)](https://www.arxiv.org/abs/2405.19567)
|2024.09.27|Junlin Guo    <br>  （Segmentation）  |[《Unleashing the Potential of SAM for Medical Adaptation via Hierarchical Decoding》   (CVPR2024)](https://arxiv.org/abs/2403.18271)
|2024.09.20|Juming Xiong    <br>  （Image Registration）  |[《RegWSI: Whole slide image registration using combined deep feature-and intensity-based methods: Winner of the ACROBAT 2023 challenge》   (Computer Methods and Programs in Biomedicine)](https://arxiv.org/pdf/2404.13108v2)
|2024.09.20|Juming Xiong    <br>  （Image Registration）|[《Unsupervised Non-rigid Histological Image Registration Guided by Keypoint Correspondences Based on Learnable Deep Features with Iterative Training》  (TMI)](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10643202)
|2024.09.20|Juming Xiong    <br>  （Image Segmentation）|[《Feature-prompting GBMSeg: One-Shot Reference Guided Training-Free Prompt Engineering for Glomerular Basement Membrane Segmentation》  (MICCAI)](https://arxiv.org/pdf/2406.16271)
|2024.09.13|Cathy Cui    <br>  （Vision-language model）  |[《Segment Everything Everywhere All at Once》   (NeurIPS 2023)](https://openreview.net/pdf?id=UHBrWeFWlL)
|2024.09.13|Cathy Cui    <br>  （Vision-language model）|[《Semantic-SAM: Segment and Recognize Anything at Any Granularity》  (ArXiv)](https://arxiv.org/abs/2307.04767)
|2024.09.13|Cathy Cui    <br>  （Vision-language model）|[《BiomedParse: a biomedical foundation model for image parsing of everything everywhere all at once》  (ArXiv)](https://arxiv.org/abs/2405.12971)
|2024. 9.6 | Ruining Deng  <br> （GAN-based application）  |[《CP2Image: Generating high-quality single-cell images using CellProfiler representations》 （MIDL2023）](https://proceedings.mlr.press/v227/ji24a.html)
|2024. 9.6 | Ruining Deng  <br> （Image Registration）  |[《Unsupervised Histological Image Registration Using Structural Feature Guided Convolutional Neural Network》 （IEEE TMI)](https://ieeexplore.ieee.org/document/9745959)
|2024. 9.6 | Ruining Deng  <br> （Vision-Language model）  |[《ViLa-MIL: Dual-scale Vision-Language Multiple Instance Learning for Whole Slide Image Classification》 （CVPR2024)](https://openaccess.thecvf.com/content/CVPR2024/papers/Shi_ViLa-MIL_Dual-scale_Vision-Language_Multiple_Instance_Learning_for_Whole_Slide_Image_CVPR_2024_paper.pdf)
|2024.08.30|Tianyuan Yao    <br>  （Vision language Model）  |[《BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models》 (ArXiv）](https://arxiv.org/pdf/2301.12597.pdf)
|2024.08.30|Tianyuan Yao    <br>  （Vision language Model）  |[《BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation》 (ArXiv）](https://arxiv.org/pdf/2201.12086.pdf)
|2024.08.30|Tianyuan Yao    <br>  （Vision language Model）  |[《Align before Fuse: Vision and Language Representation Learning with Momentum Distillation》 (ArXiv）](https://arxiv.org/pdf/2107.07651.pdf)
|2024.08.23 | Marilyn Lionts  <br> （digital pathology virtual staining）  |[《Virtual histological staining of unlabeled autopsy tissue》 （Nature Communications 2024）](https://www.nature.com/articles/s41467-024-46077-2)
|2024.08.23 | Marilyn Lionts  <br> （LLM）  |[《META-REWARDING LANGUAGE MODELS: Self-Improving Alignment with LLM-as-a-Meta-Judge》 （ArXiv 2024）](https://arxiv.org/pdf/2407.19594)
|2024.08.23 | Marilyn Lionts  <br> （AI Safety）  |[《Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?》 （ArXiv 2024）](https://arxiv.org/pdf/2407.21792)
|2024.07.26 | Junchao Zhu  <br> （pseudo label + semi-supervised learning）  |[《Co-training with High-Confidence Pseudo Labels for Semi-supervised Medical Image Segmentation》 （IJCAI 2023）](https://dl.acm.org/doi/10.24963/ijcai.2023/467)
|2024.07.26 | Junchao Zhu  <br> （pseudo label + semi-supervised learning）  |[《Conflict-Based Cross-View Consistency for Semi-Supervised Semantic Segmentation》 （CVPR2023）](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Conflict-Based_Cross-View_Consistency_for_Semi-Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf)
|2024.07.26 | Junchao Zhug  <br> （pseudo label + semi-supervised learning）  |[《Mutual learning with reliable pseudo label for semi-supervised medical image segmentation》 （MEDIA）](https://www.sciencedirect.com/science/article/pii/S1361841524000367)
|2024.07.19 | Yuechen Yang  <br> （image analysis toolbox）  |[《TIAToolbox as an end-to-end library for advanced tissue image analytics》 （ communications medicine 2022）](https://www.nature.com/articles/s43856-022-00186-5)
|2024.07.19 | Yuechen Yang  <br> （feature extraction + ML）  |[《Classification of Citrus Type Based on Leaf Image Using Shape Extraction and GLCM with the Decision Tree Method》 （IEEE 2021）](https://ieeexplore.ieee.org/abstract/document/9573252)
|2024.07.19 | Yuechen Yang  <br> （feature extraction + ML）  |[《Sliding Window Based Support Vector Machine System for Classification of Breast Cancer Using Histopathological Microscopic Images》 （IETE 2019）](https://www.tandfonline.com/doi/abs/10.1080/03772063.2019.1583610)
|2024.07.05 | Ruining Deng  <br> （Multi-modal Learning）  |[《Transcriptomics-guided Slide Representation Learning in Computational Pathology》 （CVPR2024）](https://openaccess.thecvf.com/content/CVPR2024/papers/Jaume_Transcriptomics-guided_Slide_Representation_Learning_in_Computational_Pathology_CVPR_2024_paper.pdf)
|2024.07.05 | Ruining Deng  <br> （Multi-rater Learning）  |[《Stochastic In-Context Learning for Medical Image Segmentation》 （CVPR2024）](https://openaccess.thecvf.com/content/CVPR2024/papers/Rakic_Tyche_Stochastic_In-Context_Learning_for_Medical_Image_Segmentation_CVPR_2024_paper.pdf)
|2024.07.05 | Ruining Deng  <br> （Continual Learning）  |[《Continual Self-supervised Learning: Towards Universal Multi-modal Medical Data Representation Learning》 （CVPR2024)](https://openaccess.thecvf.com/content/CVPR2024/papers/Ye_Continual_Self-supervised_Learning_Towards_Universal_Multi-modal_Medical_Data_Representation_Learning_CVPR_2024_paper.pdf)
|2024.06.21|Juming Xiong    <br>  （Image Stitching）  |[《Unsupervised Deep Image Stitching: Reconstructing Stitched Features to Images》(IEEE TRANSACTIONS ON IMAGE PROCESSING)](https://arxiv.org/pdf/2106.12859)
|2024.06.21|Juming Xiong    <br>  （Image Stitching）|[《Parallax-Tolerant Unsupervised Deep Image Stitching》](https://arxiv.org/pdf/2302.08207))
|2024.06.21|Juming Xiong    <br>  （Image Stitching）|[《Implicit Neural Image Stitching With Enhanced and Blended Feature Reconstruction》](https://arxiv.org/pdf/2309.01409)
|2024.06.14|Tianyuan Yao    <br>  （Time series foundation model）  |[《Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting》](https://arxiv.org/pdf/1912.09363.pdf)
|2024.06.14|Tianyuan Yao    <br>  （Time series foundation model）  |[《Spatial-Temporal Transformer Networks for Traffic Flow Forecasting》](https://arxiv.org/pdf/2001.02908.pdf)
|2024.06.14|Tianyuan Yao    <br>  （Time series foundation model）  |[《Foundation Models for Time Series Analysis: A Tutorial and Survey》](https://arxiv.org/pdf/2403.14735.pdf)
|2024.05.24|Marilyn Lionts    <br>  （Transformers）  |[《Improving Transformers Using Faithful Positional Encoding》 (ArXiv）](https://arxiv.org/pdf/2405.09061v1)
|2024.05.24|Marilyn Lionts    <br>  （Transformers）  |[《Zero-Shot Tokenizer Transfer》 (ArXiv）](https://arxiv.org/pdf/2405.07883#:~:text=While%20past%20work%20investigated%20n-shot%20tokenizer%20transfer%2C%20we,LMs%20from%20the%20tokenizer%20they%20were%20trained%20with.)
|2024.05.24|Marilyn Lionts    <br>  （Language Models）  |[《Observational Scaling Laws and the Predictability of Language Model Performance》 (ArXiv）](https://arxiv.org/pdf/2405.10938)
|2024.05.03|Junlin Guo    <br>  （RLHF + Large Language Model）  |[《Aligning Large Multimodal Models with Factually Augmented RLHF》 (ArXiv）](https://arxiv.org/abs/2309.14525)
|2024.05.03|Junlin Guo    <br>  （RLHF + Diffusion Model）  |[《Using Human Feedback to Fine-tune Diffusion Models without Any Reward Model》 (CVPR2024）](https://arxiv.org/abs/2311.13231)
|2024.04.26|Tianyuan Yao    <br>  （Large language Model）  |[《Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking》 (ArXiv）](https://arxiv.org/pdf/2403.09629.pdf)
|2024.04.26|Tianyuan Yao    <br>  （Large language Model）  |[《Mixture-of-Depths: Dynamically allocating compute in transformer-based language models》 (ArXiv）](https://arxiv.org/pdf/2404.02258.pdf)
|2024.04.26|Tianyuan Yao    <br>  （Large language Model）  |[《Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention》 (ArXiv）](https://arxiv.org/pdf/2404.07143.pdf)
|2024.04.19|Marilyn Lionts  <br> （Spatial Awareness LLMs）  |[《BLINK: Multimodal Large Language Models Can See but Not Perceive》 (ArXiv）](https://arxiv.org/pdf/2404.12390.pdf)
|2024.04.19|Marilyn Lionts  <br> （Spatial Awareness LLMs）  |[《Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models》 （ArXiv）](https://arxiv.org/pdf/2404.03622.pdf)
|2024.04.19|Marilyn Lionts  <br> （Adversarial LLMs）  |[《Manipulating Large Language Models to Increase Product Visibility》 （ArXiv)](https://arxiv.org/pdf/2404.07981.pdf)
|2024.04.12|Quan Liu  <br> （Small Language Model）  |[《Textbooks Are All You Need》 (ArXiv）](https://arxiv.org/abs/2306.11644)
|2024.04.12|Quan Liu  <br> （Small Language Model）  |[《Small Models are Valuable Plug-ins for Large Language Models》 （ArXiv）](https://arxiv.org/abs/2305.08848)
|2024.04.12|Quan Liu  <br> （Small Language Model）  |[《MobileVLM V2: Faster and Stronger Baseline for Vision Language Model》 （ArXiv)](https://arxiv.org/pdf/2402.03766.pdf)
|2024.04.05|Ruining Deng  <br> （Class-incremental Learning）  |[《PLOP: Learning without Forgetting for Continual Semantic Segmentation》 （CVPR2021）](https://openaccess.thecvf.com/content/CVPR2021/papers/Douillard_PLOP_Learning_Without_Forgetting_for_Continual_Semantic_Segmentation_CVPR_2021_paper.pdf)
|2024.04.05|Ruining Deng  <br> （Class-incremental Learning）  |[《Class Similarity Weighted Knowledge Distillation for Continual Semantic Segmentation》 （CVPR2022）](https://openaccess.thecvf.com/content/CVPR2022/papers/Phan_Class_Similarity_Weighted_Knowledge_Distillation_for_Continual_Semantic_Segmentation_CVPR_2022_paper.pdf)
|2024.04.05|Ruining Deng  <br> （Class-incremental Learning）  |[《CoMFormer: Continual Learning in Semantic and Panoptic Segmentation》 （CVPR2023) ](https://openaccess.thecvf.com/content/CVPR2023/papers/Cermelli_CoMFormer_Continual_Learning_in_Semantic_and_Panoptic_Segmentation_CVPR_2023_paper.pdf)
|2024.03.29|Cathy Cui  <br>  （Efficient Model）  |[《PromptKD: Unsupervised Prompt Distillation for Vision-Language Models》](https://arxiv.org/abs/2403.02781)
|2024.03.29|Cathy Cui  <br>  （Efficient Model）  |[《Omni-SMoLA: Boosting Generalist Multimodal Models with Soft Mixture of Low-rank Experts》](https://arxiv.org/pdf/2312.00968.pdf)
|2024.03.29|Cathy Cui  <br>  （Efficient Model）  |[《EfficientSAM: Leveraged Masked Image Pretraining for Efficient Segment Anything》](https://arxiv.org/pdf/2312.00863.pdf)
|2024.03.22|Juming Xiong    <br>  （Generative Model）  |[《Endora: Video Generation Models as Endoscopy Simulators》](https://arxiv.org/pdf/2403.11050.pdf)
|2024.03.22|Juming Xiong    <br>  （Image Segmentation）|[《OMG-Seg: Is One Model Good Enough For All Segmentation》(CVPR 2024)](https://arxiv.org/pdf/2401.10229.pdf)
|2024.03.22|Juming Xiong    <br>  （Image registration）|[《Modality-Agnostic Structural Image Representation Learning for Deformable Multi-Modality Medical Image Registration》(CVPR 2024)](https://arxiv.org/pdf/2402.18933.pdf)
|2024.03.15|Yucheng Tang    <br>  （Autoregressive Models）  |[《Taming Transformers for High-Resolution Image Synthesis》(CVPR 2021)](https://arxiv.org/pdf/2012.09841.pdf)
|2024.03.15|Yucheng Tang    <br>  （Autoregressive Models）  |[《Sequential Modeling Enables Scalable Learning for Large Vision Models》](https://arxiv.org/pdf/2312.00785.pdf)
|2024.03.15|Yucheng Tang    <br>  （Autoregressive Models）  |[《VILA: On Pre-training for Visual Language Models》(CVPR 2024)](https://arxiv.org/pdf/2312.07533.pdf)
|2024.03.01|Junlin Guo    <br>  （Visual Language model + Dataset denoising）  |[《Filtering, distillation, and hard negatives for vision-language pre-training》(CVPR 2023)](https://arxiv.org/pdf/2301.02280.pdf)
|2024.03.01|Junlin Guo    <br>  （Foundation model + Weakly supervised learning）  |[《Foundation Model Drives Weakly Incremental Learning for Semantic Segmentation》(CVPR 2023)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_Foundation_Model_Drives_Weakly_Incremental_Learning_for_Semantic_Segmentation_CVPR_2023_paper.pdf)
|2024.03.01|Junlin Guo    <br>  （Self-supervised Pre-training）  |[《Geometric Visual Similarity Learning in 3D Medical Image Self-supervised Pre-training》(CVPR 2023)](https://openaccess.thecvf.com/content/CVPR2023/html/He_Geometric_Visual_Similarity_Learning_in_3D_Medical_Image_Self-Supervised_Pre-Training_CVPR_2023_paper.html)
|2024.02.23|Tianyuan Yao    <br>  （Vision 'language' Model）  |[《Images Speak in Images: A Generalist Painter for In-Context Visual Learning》](https://arxiv.org/pdf/2212.02499.pdf)
|2024.02.23|Tianyuan Yao    <br>  （Machine unlearning）  |[《UnlearnCanvas: A Stylized Image Dataset to Benchmark Machine Unlearning for Diffusion Models》](https://arxiv.org/pdf/2402.11846.pdf)
|2024.02.16|Marilyn Lionts     <br>  （Unlearnable Datasets）  |[《UNLEARNABLE EXAMPLES: MAKING PERSONAL DATA UNEXPLOITABLE》(ICLR2021）](https://arxiv.org/pdf/2101.04898.pdf)
|2024.02.16|Marilyn Lionts     <br>  （Unlearnable Datasets）  |[《CUDA: Convolution-based Unlearnable Datasets》(CVPR 2023）](https://openaccess.thecvf.com/content/CVPR2023/papers/Sadasivan_CUDA_Convolution-Based_Unlearnable_Datasets_CVPR_2023_paper.pdf)
|2024.02.16|Marilyn Lionts     <br>  （Unlearnable Datasets）  |[《Unlearnable Clusters: Towards Label-agnostic Unlearnable Examples》(CVPR 2023）](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Unlearnable_Clusters_Towards_Label-Agnostic_Unlearnable_Examples_CVPR_2023_paper.pdf)
|2024.02.09|Quan Liu     <br>  （Multi-modal Large Language Models (MLLM）  |[《Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization》（ArXiv）](https://arxiv.org/pdf/2309.04669.pdf)
|2024.02.09|Quan Liu     <br>  （MLLM）  |[《GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest》(ArXiv）](https://jshilong.github.io/images/gpt4roi.pdf)
|2024.02.09|Quan Liu     <br>  （MLLM）  |[《DocPedia: Unleashing the Power of Large Multimodal Model in the Frequency Domain for Versatile Document Understanding》(ArXiv）](https://arxiv.org/pdf/2311.11810.pdf)
|2024.02.02 | Ruining Deng  <br> （Hierarchical Semantic Segmentation）  |[《Deep Hierarchical Semantic Segmentation》 （CVPR2022)](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Deep_Hierarchical_Semantic_Segmentation_CVPR_2022_paper.pdf)
|2024.02.02 | Ruining Deng  <br> （Hierarchical Semantic Segmentation）  |[《Unsupervised Hierarchical Semantic Segmentation with Multiview Cosegmentation and Clustering Transformers 》 （CVPR2022）](https://openaccess.thecvf.com/content/CVPR2022/papers/Ke_Unsupervised_Hierarchical_Semantic_Segmentation_With_Multiview_Cosegmentation_and_Clustering_Transformers_CVPR_2022_paper.pdf)
|2024.02.02 | Ruining Deng  <br> （Universal segmentation）  |[《UniverSeg: Universal Medical Imaging Segmentation》 （ICCV2023](https://arxiv.org/pdf/2304.06131.pdf)
|2024.01.26|Can(Cathy) Cui     <br>  （Vision Language Model）  |[《LISA: Reasoning Segmentation via Large Language Model》 （ArXiv）](https://arxiv.org/pdf/2308.00692.pdf)
|2024.01.26|Can(Cathy) Cui     <br>  （Vision Language Model）  |[《Making Large Multimodal Models Understand Arbitrary Visual Prompts 》(ArXiv）](https://arxiv.org/pdf/2312.00784.pdf)
|2024.01.26|Can(Cathy) Cui     <br>  （Network Structure）  |[《U-Mamba Enhancing Long-range Dependency for Biomedical Image Segmentation》(ArXiv）](https://wanglab.ai/u-mamba.html)
|2024.01.12 | Yucheng Tang  <br> （Efficient ViT）  |[《EfficientViT: Multi-Scale Linear Attention for High-Resolution Dense Prediction》 （ICCV 2023）](https://arxiv.org/pdf/2205.14756.pdf)
|2024.01.12 | Yucheng Tang  <br> Sparse ViT）  |[《SparseViT: Revisiting Activation Sparsity for Efficient High-Resolution Vision Transformer》 (CVPR) 2023）](https://arxiv.org/pdf/2303.17605.pdf)
|2024.01.12 | Yucheng Tang  <br> （Open-Vocabulary SAM）  |[《Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively》](https://arxiv.org/pdf/2401.02955.pdf)
|2023.11.17 | Dr. Huo  <br> （Spatial Transcriptomics）  |[《Visualization and Analysis of Gene Expression in Tissue Sections by Spatial Transcriptomics》 （Science 2016）](https://www.science.org/doi/10.1126/science.aaf2403?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub%20%200pubmed)
|2023.11.17 | Dr. Huo  <br> （Spatial Transcriptomics）  |[《Spatially Resolved Transcriptomes—Next Generation Tools for Tissue Exploration》 （BioEssay 2020）](https://onlinelibrary.wiley.com/doi/full/10.1002/bies.201900221)
|2023.11.17 | Dr. Huo  <br> （Spatial Transcriptomics）  |[《Alignment and Integration of Spatial Transcriptomics Data》 （Nature Method 2022）](https://www.nature.com/articles/s41592-022-01459-6)
|2023.11.10 | Quan Liu  <br> （Vision Language Foundation Model）  |[《Multimodal Few-Shot Learning with Frozen Language Models》 （NeruIPS 2021）](https://arxiv.org/pdf/2106.13884.pdf)
|2023.11.10 | Quan Liu  <br> （Vision Language Foundation Model）  |[《Frozen Transformers in Language Models Are Effective Visual Encoder Layers》 （arxiv）](https://arxiv.org/pdf/2310.12973.pdf)
|2023.11.10 | Quan Liu  <br> （Tranformer CNN backbone comparison）  |[《ConvNets Match Vision Transformers at Scale》 （DeepMind）](https://arxiv.org/pdf/2310.16764.pdf)
|2023.11.03 | Junlin Guo  <br> （Long-Tailed Learning + Knowledge Distillation）  |[《Long-Tailed Visual Recognition via Self-Heterogeneous Integration with Knowledge Excavation》 （CVPR 2023）](https://arxiv.org/pdf/2304.01279.pdf)
|2023.11.03 | Junlin Guo  <br> （Universal instance cell segmentation）  |[《Cellpose: a generalist algorithm for cellular segmentation》 （Nature. 2021）](https://www.nature.com/articles/s41592-020-01018-x)
|2023.11.03 | Junlin Guo  <br> （Universal instance cell segmentation + Harmony）  |[《MEDIAR: Harmony of Data-Centric and Model-Centric for Multi-Modality Microscopy》 （NeurIPS 2022）](http://arxiv.org/abs/2212.03465)
|2023.10.27 | Marilyn Lionts  <br> （Variational Autoencoders and Active Learning）  |[《An Active Learning Method Based on Variational Autoencoder and DBSCAN Clustering》 （2021）](https://downloads.hindawi.com/journals/cin/2021/9952596.pdf)
|2023.10.27 | Marilyn Lionts  <br> （Variational Autoencoders and Active Learning）  |[《The Power of Ensembles for Active Learning in Image Classification》 （CVPR 2018）](https://openaccess.thecvf.com/content_cvpr_2018/papers/Beluch_The_Power_of_CVPR_2018_paper.pdf)
|2023.10.27 | Marilyn Lionts  <br> （Variational Autoencoders and Active Learning）  |[《Variational Adversarial Active Learning》 （ICCV 2019）](https://openaccess.thecvf.com/content_ICCV_2019/papers/Sinha_Variational_Adversarial_Active_Learning_ICCV_2019_paper.pdf)
|2023.10.20 | Can(Cathy) Cui  <br> （Anomaly Detection and Localization）  |[《Anomaly Detection via Reverse Distillation from One-Class Embedding》 （CVPR2022）](https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_Anomaly_Detection_via_Reverse_Distillation_From_One-Class_Embedding_CVPR_2022_paper.pdf)
|2023.10.20 | Can(Cathy) Cui  <br> （Anomaly Detection and Localization）  |[《Revisiting Reverse Distillation for Anomaly Detection》 （CVPR2023）](https://openaccess.thecvf.com/content/CVPR2023/papers/Tien_Revisiting_Reverse_Distillation_for_Anomaly_Detection_CVPR_2023_paper.pdf)
|2023.10.20 | Can(Cathy) Cui  <br> （Anomaly Detection and Localization）  |[《ReContrast: Domain-Specific Anomaly Detection via Contrastive Reconstruction》 （NeurIPS）](https://arxiv.org/abs/2306.02602)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model）  |[《Flamingo: a Visual Language Model for Few-Shot Learning》 (DeepMind)](https://arxiv.org/abs/2204.14198)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model）  |[《PaLM: Scaling Language Modeling with Pathways》 (Google)](https://arxiv.org/abs/2204.02311)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model）  |[《PaLM-E: An Embodied Multimodal Language Model》 (Google)](https://arxiv.org/abs/2303.03378)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model）  |[《GPT-4 Technical Report 》 (OPEN AI)](https://arxiv.org/abs/2303.08774)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model）  |[《LLaMA: Open and Efficient Foundation Language Models》 (Meta)](https://arxiv.org/abs/2302.13971)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model）  |[《LLAVA: Visual Instruction Tuning》 (Microsoft, UWM)](https://arxiv.org/abs/2304.08485)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model --- Medical）  |[《Med-PALM : Large Language Models Encode Clinical Knowledge》 (Google)](https://arxiv.org/abs/2212.13138)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model --- Medical）  |[《BioMedCLIP: LARGE-SCALE DOMAIN-SPECIFIC PRETRAINING FOR BIOMEDICAL VISION-LANGUAGE PROCESSING》 (Microsoft)](https://arxiv.org/pdf/2303.00915.pdf)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model --- Medical）  |[《LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day 》 (Microsoft)](https://arxiv.org/pdf/2306.00890.pdf)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model --- Medical）  |[《Med-Flamingo: MED-FLAMINGO: A MULTIMODAL MEDICAL FEWSHOT LEARNER 》 (Stanford)](https://arxiv.org/pdf/2307.15189.pdf)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model --- Medical）  |[《Towards Generalist Foundation Model for Radiology 》 (Shanghai AI Lab)](https://arxiv.org/pdf/2308.02463.pdf)
|2023.10.6 | Dr. Huo  <br> （Vision language model）  |[《CLIP-Driven Universal Model for Organ Segmentation and Tumor Detection》 （arxiv）](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_CLIP-Driven_Universal_Model_for_Organ_Segmentation_and_Tumor_Detection_ICCV_2023_paper.pdf)
|2023.10.6 | Dr. Huo  <br> （Fast data curation）  |[《Annotating 8,000 Abdominal CT Volumes for Multi-Organ Segmentation in Three Weeks》 （ICCV 2023）](https://arxiv.org/pdf/2305.09666.pdf)
|2023.10.6 | Dr. Huo  <br> （Tranformer backbone）  |[《UNesT: Local Spatial Representation Learning with Hierarchical Transformer for Efficient Medical Segmentation》 （MeDIA 2023）](https://browse.arxiv.org/pdf/2209.14378.pdf)
|2023.9.22 | Tianyuan Yao  <br> （Vision language model）  |[《BridgeTower: Building Bridges Between Encoders in Vision-Language Representation Learning》 （AAAI 2023）](https://arxiv.org/pdf/2206.08657.pdf)
|2023.9.22 | Tianyuan Yao  <br> （Vision language model）  |[《PMC-CLIP: Contrastive Language-Image Pre-training using Biomedical Documents》 （MICCAI 2023）](https://arxiv.org/pdf/2303.07240.pdf)
|2023.9.22 | Tianyuan Yao  <br> （Representation disentanglement + segmentation）  |[《Directional Connectivity-based Segmentation of Medical Images》 （CVPR 2023）](https://arxiv.org/ftp/arxiv/papers/2304/2304.00145.pdf)
|2023.9.22 | Tianyuan Yao  <br> （Semi-supervised Segmentation）  |[《Orthogonal Annotation Benefits Barely-supervised Medical Image Segmentation》 （CVPR 2023）](https://arxiv.org/pdf/2303.13090.pdf)
|2023.9.15 | Ruining Deng  <br> （Prompt-based Segmentation）  |[《Incrementer: Transformer for Class-Incremental Semantic Segmentation with Knowledge Distillation Focusing on Old Class》 （CVPR2023）](https://openaccess.thecvf.com/content/CVPR2023/papers/Shang_Incrementer_Transformer_for_Class-Incremental_Semantic_Segmentation_With_Knowledge_Distillation_Focusing_CVPR_2023_paper.pdf)
|2023.9.15 | Ruining Deng  <br> （Prompt-based Segmentation）  |[《SegPrompt: Boosting Open-world Segmentation via Category-level Prompt Learning》 （ICCV）](https://arxiv.org/pdf/2308.06531.pdf)
|2023.9.15 | Ruining Deng  <br> （Prompt-based Segmentation）  |[《ProSFDA: Prompt Learning based Source-free Domain Adaptation for Medical Image Segmentation》 （ArXiv）](https://arxiv.org/abs/2211.11514)
|2023.9.08|Dr. Huo     <br>  （Text-to-image Segmentation）  |[《Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion Models》 （ArXiv）](https://arxiv.org/pdf/2303.04803.pdf)
|2023.9.08|Dr. Huo     <br>  （Fundation Models）  |[《DINOv2 from Meta AI – Finally a Foundational Model in Computer Vision》 （Web Site）](https://aipapersacademy.com/dinov2-from-meta-ai-finally-a-foundational-model-in-computer-vision/) [(ArXiv)](https://arxiv.org/abs/2304.07193)
|2023.9.08|Dr. Huo     <br>  （Fundation Models）  |[《SAM-Med2D》 （ArXiv）](https://arxiv.org/pdf/2308.16184.pdf)
|2023.8.25|Quan Liu     <br>  （Self-supervised Learning）  |[《EMP-SSL: Towards Self-Supervised Learning in One Training Epoch》 （CVPR 2023）](https://arxiv.org/abs/2304.03977)
|2023.8.25|Quan Liu     <br>  （Vision language model + zero-shot learning）  |[《Visual Language Pretrained Multiple Instance Zero-Shot Transfer for Histopathology Images》 （CVPR 2023）](https://openaccess.thecvf.com/content/CVPR2023/papers/Lu_Visual_Language_Pretrained_Multiple_Instance_Zero-Shot_Transfer_for_Histopathology_Images_CVPR_2023_paper.pdf)
|2023.8.25|Quan Liu     <br>  （Image perturbation）  |[《Revisiting Weak-to-Strong Consistency in Semi-Supervised Semantic Segmentation》 （CVPR 2023）](https://arxiv.org/pdf/2208.09910.pdf)





## Pool of great papers from the team (Senior folks can drop papers here as potential papers to review)
1. Ye, Shuquan, et al. "Improving Commonsense in Vision-Language Models via Knowledge Graph Riddles." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023. [from Yuankai Huo]

1. Xie, Ronald, et al. "MAESTER: Masked Autoencoder Guided Segmentation at Pixel Resolution for Accurate, Self-Supervised Subcellular Structure Recognition." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023. [from Yuankai Huo]

1. Huang, Zhi, et al. "A visual–language foundation model for pathology image analysis using medical Twitter." Nature Medicine (2023): 1-10. [from Yuankai Huo]
